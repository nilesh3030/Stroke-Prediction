{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyMwrsSbvjaTU9CDOZIezN23",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nilesh3030/Stroke-Prediction/blob/main/Adding_weather_data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jR5TeV4cB2wC"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "pd.set_option ('display.max_columns', None)\n",
        "pd.set_option ('display.max_rows', None)\n",
        "\n",
        "raw_data = pd.read_csv('/content/drive/MyDrive/Stroke_Prediction/Data/stroke_case.csv', low_memory = False)\n",
        "\n",
        "unique_patient_address = pd.read_csv('/content/drive/MyDrive/Stroke_Prediction/Data/unique_address_with_location.csv', encoding = 'euc_kr')\n",
        "\n",
        "weather_data1 = pd.read_csv('/content/drive/MyDrive/Stroke_Prediction/Data/Weather_Data/OBS_AWS_TIM_202201-02.csv', encoding = 'euc_kr')\n",
        "weather_data2 = pd.read_csv('/content/drive/MyDrive/Stroke_Prediction/Data/Weather_Data/OBS_AWS_TIM_202203-04.csv', encoding = 'euc_kr')\n",
        "weather_data3 = pd.read_csv('/content/drive/MyDrive/Stroke_Prediction/Data/Weather_Data/OBS_AWS_TIM_202205-06.csv', encoding = 'euc_kr')"
      ],
      "metadata": {
        "id": "pDzuJYzcPImS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Processing the weather data"
      ],
      "metadata": {
        "id": "19egvYuTlAj_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vars_to_drop = ['풍향(deg)', '해면기압(hPa)']\n",
        "\n",
        "weather_data1 = weather_data1.drop(vars_to_drop, axis = 1)\n",
        "weather_data2 = weather_data2.drop(vars_to_drop, axis = 1)\n",
        "weather_data3 = weather_data3.drop(vars_to_drop, axis = 1)"
      ],
      "metadata": {
        "id": "qs1jVWnQxZq4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "weather_temp = weather_data1.append(weather_data2)\n",
        "weather_data = weather_temp.append(weather_data3)"
      ],
      "metadata": {
        "id": "e6G6l2XlyPwE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(weather_data1.shape)\n",
        "print(weather_data2.shape)\n",
        "print(weather_data3.shape)\n",
        "print(weather_data.shape)"
      ],
      "metadata": {
        "id": "HXii5UkJyejL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "weather_data.columns = ['Branch_code', 'Branch_name', 'Date_time', 'Temperature', 'Wind_Speed(m/s)', 'Precipitation(mm)', 'Pressure(hPa)', 'Humidity(%)']"
      ],
      "metadata": {
        "id": "pb478GQ_XH-p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "weather_data['Date_time'] = pd.to_datetime(weather_data['Date_time']).dt.strftime('%Y-%m-%d %H')"
      ],
      "metadata": {
        "id": "tVz6ltcXdC-j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "weather_data.head()"
      ],
      "metadata": {
        "id": "8O8TMCp5dNZt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dedup the data to handle the repeating values on branch datetime level\n",
        "\n",
        "weather_data = weather_data.drop_duplicates(subset=['Branch_name', 'Date_time'])\n",
        "\n",
        "weather_data.shape"
      ],
      "metadata": {
        "id": "eNhVhD23zvdG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "null_variables = round((weather_data.isna().sum()/len(weather_data))*100,2)\n",
        "null_variables"
      ],
      "metadata": {
        "id": "13_ep7mS1-tO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#dropping the pressure variable as it has a greater % of nulls\n",
        "\n",
        "weather_data = weather_data.drop(['Pressure(hPa)'], axis = 1)"
      ],
      "metadata": {
        "id": "UQxSYAvB2Uhs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "weather_data.to_csv('/content/drive/MyDrive/Stroke_Prediction/Data/Weather_Data/cleaned_weather_data.csv', encoding = 'euc_kr')"
      ],
      "metadata": {
        "id": "C1OyUWzVUnYX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unique_station = weather_data.groupby(['Branch_name']).size().reset_index(name='Freq')"
      ],
      "metadata": {
        "id": "r5AiQFKvZfFb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unique_station.shape"
      ],
      "metadata": {
        "id": "UAFkpbvvVD0C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Adding the location of weather station and assigning the weather station which is nearest from the patient's location"
      ],
      "metadata": {
        "id": "xesWHhjjY9C8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "weather_station_location = pd.read_excel('/content/drive/MyDrive/Stroke_Prediction/Data/Meterological_branch_and_Location.xlsx')"
      ],
      "metadata": {
        "id": "54NXPeDUY8Qs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "weather_station_location.head()"
      ],
      "metadata": {
        "id": "_XkUWfYLZVqZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Stripping the whitespace so that join can be done easily\n",
        "weather_station_location['Branch Name'] = weather_station_location['Branch Name'].str.strip()\n",
        "unique_station['Branch_name'] = unique_station['Branch_name'].str.strip()"
      ],
      "metadata": {
        "id": "dN2XOoE0bUgR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Attaching the location info to unique stations\n",
        "unique_station_location = pd.merge(unique_station, weather_station_location,  how='inner', left_on=['Branch_name'], right_on = ['Branch Name'])"
      ],
      "metadata": {
        "id": "97aJSibVZyOq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Shape should be same as that ensures that we have location info for all the unique weather station\n",
        "unique_station_location.shape"
      ],
      "metadata": {
        "id": "d9nayiTbbx1Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unique_station_location = unique_station_location[['Branch Name', 'Latitude', 'Longitude']]\n",
        "unique_station_location.head()"
      ],
      "metadata": {
        "id": "-iWQp15Db-eI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Attaching the branch which is nearest from the patient's location\n",
        "import numpy as np\n",
        "from scipy.spatial.distance import cdist\n",
        "\n",
        "unique_patient_address[\"Branch Name\"] = pd.Series([unique_station_location[\"Branch Name\"].iloc[np.argmin(x)] for x in cdist(unique_patient_address[[\"latitude\", \"longitude\"]], unique_station_location[[\"Latitude\", \"Longitude\"]])])\n"
      ],
      "metadata": {
        "id": "OcAYbmf0d1bj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unique_patient_address.head()"
      ],
      "metadata": {
        "id": "3UeqI28ve6lE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## We will create the data on 'id' level where we map the nearest branch info for each ids\n",
        "id_level_data = raw_data[['jaenan_sn', 'address_si', 'address_gu', 'address_dong', 'call_d', 'call_t']]\n",
        "id_level_data['Address'] = id_level_data['address_si'] + \", \" + id_level_data['address_gu'] + \", \" +  id_level_data['address_dong']\n",
        "\n",
        "print(id_level_data.shape)"
      ],
      "metadata": {
        "id": "Hu4FmB_ZfPEB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nearest_branch_super = id_level_data.merge(unique_patient_address, on = 'Address')\n",
        "print(nearest_branch_super.shape)"
      ],
      "metadata": {
        "id": "-VPS2rEcg4Hm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Processing the Nearest Branch data"
      ],
      "metadata": {
        "id": "ZJfhFvDPlKZM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(nearest_branch_super.shape)\n",
        "nearest_branch_super.head()"
      ],
      "metadata": {
        "id": "nohSfeo1RQhp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nearest_branch_super.columns"
      ],
      "metadata": {
        "id": "9bIeEAG4RtFV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vars = ['jaenan_sn','call_d', 'call_t', 'latitude', 'longitude', 'Branch Name']\n",
        "nearest_branch = nearest_branch_super[vars]\n",
        "#rename the branch name to weather station######\n",
        "#'latitude', 'longitude' are the locations for the address i.e. patient location\n",
        "# 'Latitude', 'Longitude' are location respective to branch address"
      ],
      "metadata": {
        "id": "DJP7MEMmRvFv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "convert_dict = {'call_d': str,\n",
        "                'call_t': str}\n",
        " \n",
        "nearest_branch = nearest_branch.astype(convert_dict)\n",
        "\n",
        "nearest_branch[\"Datetime_patient\"] = nearest_branch[\"call_d\"] + nearest_branch[\"call_t\"]"
      ],
      "metadata": {
        "id": "tKMJL4koSYCP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_datetime(row):\n",
        "  try:\n",
        "    if len(row['Datetime_patient']) == 11 or len(row['Datetime_patient']) == 12:\n",
        "      return(pd.to_datetime(row['Datetime_patient'], format = '%Y%m%d%H%M'))\n",
        "  except: \n",
        "    return(np.nan)\n",
        "\n",
        "\n",
        "nearest_branch['Datetime_converted'] = nearest_branch.apply(lambda row: convert_datetime(row), axis=1)"
      ],
      "metadata": {
        "id": "6ltTVBUOVDXe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nearest_branch['Datetime_converted'] = nearest_branch['Datetime_converted'].dt.strftime('%Y-%m-%d %H')"
      ],
      "metadata": {
        "id": "ivaLO-mLbmq2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(nearest_branch.shape)\n",
        "nearest_branch.head()"
      ],
      "metadata": {
        "id": "1qSc0o63UYlj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Combining weather and nearest-branch data"
      ],
      "metadata": {
        "id": "51IBkwDWlQXX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "new_df = pd.merge(nearest_branch, weather_data,  how='left', left_on=['Branch Name','Datetime_converted'], right_on = ['Branch_name','Date_time'])"
      ],
      "metadata": {
        "id": "Ew6PwCUYiA-W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(new_df.shape)\n",
        "new_df.head()"
      ],
      "metadata": {
        "id": "HVZ7qdWTij5S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "null_variables = round((new_df.isna().sum()/len(new_df))*100,2)\n",
        "null_variables"
      ],
      "metadata": {
        "id": "exhsgUgw1uqF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_df[new_df.isnull().any(axis=1)].head(10)"
      ],
      "metadata": {
        "id": "_VdzOLndCK7I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clean_data_with_weather_variables = new_df#.dropna()\n",
        "clean_data_with_weather_variables.shape"
      ],
      "metadata": {
        "id": "rYPYL30Akecd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Filtering the raw data and adding the cleaned weather data"
      ],
      "metadata": {
        "id": "29YIVfwblaju"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# There are many junk columns that have been added so we will remove all of them \n",
        "raw_data = raw_data.loc[:,:'pti2']\n",
        "print(raw_data.shape)"
      ],
      "metadata": {
        "id": "o4QSJYHikmzB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cat_vars_final = ['cv_cc',\n",
        "'cv_etc',\n",
        "'cv2_cc',\n",
        "'cv2_phx_yn',\n",
        "'cv2_act',\n",
        "'sex',\n",
        "'sx1',\n",
        "'sx2',\n",
        "'sx3',\n",
        "'sx4',\n",
        "'sx5',\n",
        "'medical_history',\n",
        "'stroke',\n",
        "'obstacle2',\n",
        "'cv2_cphss']"
      ],
      "metadata": {
        "id": "xQAA_EHPl6GZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# final numerical variables based on our selection\n",
        "num_vars_final = ['jaenan_sn', 'age',\n",
        "'dbp1',\n",
        "'sbp1',\n",
        "'pr1',\n",
        "'rr1',\n",
        "'bt1',\n",
        "'spo2_1',\n",
        "'dbp2',\n",
        "'sbp2',\n",
        "'pr2',\n",
        "'rr2',\n",
        "'bt2',\n",
        "'spo2_2']"
      ],
      "metadata": {
        "id": "fqhlZerRmqBz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_variables = []\n",
        "for var in cat_vars_final:\n",
        "  final_variables.append(var)\n",
        "\n",
        "for var in num_vars_final:\n",
        "  final_variables.append(var)"
      ],
      "metadata": {
        "id": "OsuPe46Pmsjo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filtered_data = raw_data[final_variables]\n",
        "filtered_data.shape"
      ],
      "metadata": {
        "id": "LijI5INNmt22"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Joining the final data with the cleaned weather data"
      ],
      "metadata": {
        "id": "6lTGhw0ZngC_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "final_data = pd.merge(filtered_data, clean_data_with_weather_variables,  how='inner', on = 'jaenan_sn')"
      ],
      "metadata": {
        "id": "0KJ44CTpnP9x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(final_data.shape)\n",
        "final_data.head()"
      ],
      "metadata": {
        "id": "xpLlJ6zen9tV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Translating and cleaning the final data"
      ],
      "metadata": {
        "id": "6GjR2tJXoKN1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install googletrans==4.0.0-rc1"
      ],
      "metadata": {
        "id": "gvtRteaqmMxC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from googletrans import Translator\n",
        "\n",
        "translator = Translator()\n",
        "translations = {}\n",
        "for column in cat_vars_final:\n",
        "    unique = final_data[column].unique()\n",
        "    for element in unique:\n",
        "        translations[element] = translator.translate(element).text\n"
      ],
      "metadata": {
        "id": "EmgmsCIal__t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "translations.pop(np.nan)\n",
        "\n",
        "### Updating the incorrect translations in the translation dictionary\n",
        "\n",
        "translations.update({'심,뇌혈관계':'Heart, cerebrovascular',\n",
        "'발음이상':'strange pronunciation',\n",
        "'사지 저림':'numb feet and arms',\n",
        "'음성':'negative',\n",
        "'양성':'positive',\n",
        "'남':'male',\n",
        "'어지러움':'Dizziness',\n",
        "'전신쇠약':'body weekness',\n",
        "'오심':'misdiagnosis',\n",
        "'심계항진':'Palpitations',\n",
        "'질출혈':'Vaginal blooding'})\n",
        "\n",
        "final_data.replace(translations, inplace=True)"
      ],
      "metadata": {
        "id": "4LNpcWY8mQzP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vars = ['positive', 'negative']\n",
        "final_data = final_data.loc[final_data['cv2_cphss'].isin(vars)]\n",
        "\n",
        "final_data.shape"
      ],
      "metadata": {
        "id": "QnmyklqUmeER"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Replacing the target varibles with 0, 1 \n",
        "final_data['cv2_cphss'].replace(vars , [1, 0], inplace=True)"
      ],
      "metadata": {
        "id": "ThEyYlx2m6V9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# we will replace the junk values with the nan\n",
        "replace_values = {999.0 : np.nan, 999.9 : np.nan, 943.0 : np.nan, 9999.0 : np.nan, 7777.0 : np.nan, 6666.0 : np.nan, 770.0 : np.nan} \n",
        "final_data = final_data.replace(replace_values)"
      ],
      "metadata": {
        "id": "18cBZUufol5W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "null_variables = round((final_data.isna().sum()/len(final_data))*100,2)\n",
        "#null_variables"
      ],
      "metadata": {
        "id": "HdhtIr85oqLl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def spasm(row):  \n",
        "    if row['sx1'] == 'Spasm/seizure' or row['sx2'] == 'Spasm/seizure' or row['sx3'] == 'Spasm/seizure' or row['sx4'] == 'Spasm/seizure' or row['sx5'] == 'Spasm/seizure':\n",
        "        return 1\n",
        "    return 0\n",
        "\n",
        "def dizziness(row):  \n",
        "    if row['sx1'] == 'Dizziness' or row['sx2'] == 'Dizziness' or row['sx3'] == 'Dizziness' or row['sx4'] == 'Dizziness' or row['sx5'] == 'Dizziness':\n",
        "        return 1\n",
        "    return 0\n",
        "\n",
        "def faint(row):  \n",
        "    if row['sx1'] == 'faint' or row['sx2'] == 'faint' or row['sx3'] == 'faint' or row['sx4'] == 'faint' or row['sx5'] == 'faint':\n",
        "        return 1\n",
        "    return 0\n",
        "\n",
        "def consciousness(row):  \n",
        "    if row['sx1'] == 'Consciousness' or row['sx2'] == 'Consciousness' or row['sx3'] == 'Consciousness' or row['sx4'] == 'Consciousness' or row['sx5'] == 'Consciousness':\n",
        "        return 1\n",
        "    return 0\n",
        "\n",
        "def paralysis(row):  \n",
        "    if row['sx1'] == 'paralysis' or row['sx2'] == 'paralysis' or row['sx3'] == 'paralysis' or row['sx4'] == 'paralysis' or row['sx5'] == 'paralysis':\n",
        "        return 1\n",
        "    return 0\n",
        "\n",
        "def disease_history(row):  \n",
        "    if row['hypertension'] == 'Yes' or row['diabetes'] == 'Yes' or row['chest_disease'] == 'Yes' or row['heart_disease'] == 'Yes' or row['tuberculosis'] == 'Yes'or row['hepatitis'] == 'Yes' or row['liver'] == 'Yes' or row['allergy'] == 'Yes' or row['cancer'] == 'Yes' or row['renal_failure'] == 'Yes':\n",
        "        return 1\n",
        "    return 0\n",
        "\n",
        "final_data['Spasm'] = final_data.apply(lambda row: spasm(row), axis=1)\n",
        "final_data['Dizziness'] = final_data.apply(lambda row: dizziness(row), axis=1)\n",
        "final_data['Faint'] = final_data.apply(lambda row: faint(row), axis=1)\n",
        "final_data['Consciousness'] = final_data.apply(lambda row: consciousness(row), axis=1)\n",
        "final_data['Paralysis'] = final_data.apply(lambda row: paralysis(row), axis=1)"
      ],
      "metadata": {
        "id": "ZSLviov_o0XP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_data.columns"
      ],
      "metadata": {
        "id": "QlEsi07XoeEp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_data = final_data.drop(['sx1', 'sx2', 'sx3', 'sx4', 'sx5', 'cv2_cc', 'cv2_phx_yn', 'jaenan_sn', 'call_d',\n",
        "       'call_t', 'latitude', 'longitude', 'Branch Name', 'Datetime_patient', 'Datetime_converted', 'Branch_code',\n",
        "       'Branch_name', 'Date_time', 'Humidity(%)'], axis=1) #dropping the humidity as experiments have shown that it is not important\n",
        "\n",
        "print(final_data.shape)\n",
        "final_data.head()"
      ],
      "metadata": {
        "id": "agKCxInmpDB6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing few models"
      ],
      "metadata": {
        "id": "5V6ITtf-rMQp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_cat_vars = ['cv_cc', 'cv_etc', 'cv2_act', 'sex', 'medical_history', 'stroke', 'obstacle2']\n",
        "final_data[model_cat_vars] = final_data[model_cat_vars].apply(lambda x: pd.factorize(x)[0])\n",
        "\n",
        "final_data.head()"
      ],
      "metadata": {
        "id": "h931q9u5rXHW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# removing the 2nd vital counts and dropping na values\n",
        "\n",
        "model_data = final_data.drop(['dbp2', 'sbp2', 'pr2', 'rr2', 'bt2', 'spo2_2'], axis=1)\n",
        "\n",
        "model_data = model_data.dropna()\n",
        "model_data.shape"
      ],
      "metadata": {
        "id": "PdO-DwxUrvYJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_data.cv2_cphss.value_counts()"
      ],
      "metadata": {
        "id": "sbMJYbJirO_v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Data splitting and scaling\n",
        "from sklearn.feature_selection import RFE\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import preprocessing\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "X = model_data.iloc[:,model_data.columns != 'cv2_cphss']\n",
        "y = model_data.cv2_cphss\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=5, stratify=y)"
      ],
      "metadata": {
        "id": "7zEtWc__rlvR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install lazypredict"
      ],
      "metadata": {
        "id": "hanTr7thsaRx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from lazypredict.Supervised import LazyClassifier\n",
        "\n",
        "clf = LazyClassifier(verbose=0, ignore_warnings=True, custom_metric=None)\n",
        "models,predictions = clf.fit(X_train, X_test, y_train, y_test)\n",
        "models"
      ],
      "metadata": {
        "id": "4OHpTGdXsZi5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# importing random forest classifier from ensemble module\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# creating a RF classifier\n",
        "clf = RandomForestClassifier(n_estimators = 100, max_features = 'sqrt', max_depth = 5, min_samples_leaf = 3, min_samples_split = 5) \n",
        " \n",
        "# Training the model on the training dataset\n",
        "# fit function is used to train the model using the training sets as parameters\n",
        "clf.fit(X_train, y_train)\n",
        " \n",
        "# performing predictions on the test dataset\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "# metrics are used to find accuracy or error\n",
        "train_acc = clf.score(X_train, y_train)\n",
        "print(\"The Accuracy for Training Set is {}\".format(train_acc*100))\n",
        "\n",
        "test_acc = accuracy_score(y_test, y_pred)\n",
        "print(\"The Accuracy for Test Set is {}\".format(test_acc*100))\n",
        "\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "id": "zkx7GizjsoC1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature_imp = pd.Series(clf.feature_importances_, index = X_train.columns).sort_values(ascending = False)\n",
        "feature_imp"
      ],
      "metadata": {
        "id": "AqsZ9CWLsrRR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_data.to_csv('/content/drive/MyDrive/Stroke_Prediction/Data/model_data.csv')"
      ],
      "metadata": {
        "id": "vuUGAnqVS7Rj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}