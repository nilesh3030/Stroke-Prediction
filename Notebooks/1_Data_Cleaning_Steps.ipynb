{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyNotkna0CLcUOWZESivAd2E",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nilesh3030/Stroke-Prediction/blob/main/Notebooks/1_Data_Cleaning_Steps.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aQ2cvEci44VR"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('/content/drive/MyDrive/Stroke_Prediction/Data/stroke_case.csv', low_memory = False) ## Change the file name\n",
        "pd.set_option ('display.max_columns', None)\n",
        "pd.set_option ('display.max_rows', None)\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "OHK94G-x496s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.shape)\n",
        "#df.head()\n",
        "len(df.jaenan_sn.unique())"
      ],
      "metadata": {
        "id": "EM89H-uP4--G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# There are many junk columns that have been added so we will remove all of them \n",
        "df = df.loc[:,:'pti2']\n",
        "print(df.shape)"
      ],
      "metadata": {
        "id": "fpOJO7tF5HXd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dedup the data \n",
        "df = df.drop_duplicates(subset=['jaenan_sn'])\n",
        "print(df.shape)"
      ],
      "metadata": {
        "id": "edzZILpX5KcK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "missing_variables = round((df.isna().sum()/len(df))*100,2)\n",
        "missing_variables = missing_variables.loc[lambda x : x >= 30]\n",
        "\n",
        "var_to_remove = missing_variables.index\n",
        "\n",
        "len(var_to_remove)"
      ],
      "metadata": {
        "id": "MSNDTdUB5YzZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "var_to_remove = [e for e in var_to_remove if e not in ('sx2', 'sx3', 'sx4', 'sx5')]\n",
        "\n",
        "len(var_to_remove)"
      ],
      "metadata": {
        "id": "logfZCm45iN2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = df.drop(columns= var_to_remove)"
      ],
      "metadata": {
        "id": "UwTl6g6e5k_g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(data.shape)"
      ],
      "metadata": {
        "id": "1EqJ3P1h5nk9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# make list of numerical variables\n",
        "num_vars = [var for var in data.columns if data[var].dtypes != 'O']\n",
        "\n",
        "print('Number of numerical variables: ', len(num_vars))\n",
        "\n",
        "# visualise the numerical variables\n",
        "data[num_vars].head()"
      ],
      "metadata": {
        "id": "Dze9DYix5qvx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# capture categorical variables in a list\n",
        "cat_vars = [var for var in data.columns if data[var].dtypes == 'O']\n",
        "\n",
        "print('Number of categorical variables: ', len(cat_vars))\n",
        "\n",
        "# let's visualise the values of the categorical variables\n",
        "data[cat_vars].head()"
      ],
      "metadata": {
        "id": "Xe3lfpIL5v2q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cat_vars_final = ['cv_cc',\n",
        "#'cv_etc',\n",
        "'cv2_cc',\n",
        "'cv2_phx_yn',\n",
        "'cv2_act',\n",
        "#'cv2_phss',\n",
        "#'cv2_laphss',\n",
        "#'cv2_laphss_asym',\n",
        "#'cv2_laphss_seizure',\n",
        "#'cv2_laphss_bst',\n",
        "'sex',\n",
        "'sx1',\n",
        "'sx2',\n",
        "'sx3',\n",
        "'sx4',\n",
        "'sx5',\n",
        "'medical_history',\n",
        "'stroke',\n",
        "'obstacle2',\n",
        "'cv2_cphss',\n",
        "# Below are the disease variables that we are adding the for phase 2\n",
        "'hypertension',\n",
        "'diabetes',\n",
        "'chest_disease',\n",
        "'heart_disease',\n",
        "'tuberculosis',\n",
        "'hepatitis',\n",
        "'liver',\n",
        "'allergy',\n",
        "'cancer',\n",
        "'renal_failure',\n",
        "'triage']"
      ],
      "metadata": {
        "id": "as7cZ3bg5xFW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Google API will not work on the bulk data so we need to limit the data we pass in one go and hence we will first take the neccessary columns that we need and then make a list of unique values from these columns so that we can control the number of records that we pass through the Google API."
      ],
      "metadata": {
        "id": "P8f4_5n36F17"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "unique_list = []\n",
        "for column in cat_vars_final:\n",
        "    unique = df[column].unique()\n",
        "    for element in unique:\n",
        "      unique_list.append(element)"
      ],
      "metadata": {
        "id": "4Aaa9O1T6BBJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(unique_list))\n",
        "unique_list = set(unique_list)\n",
        "print(len(unique_list))"
      ],
      "metadata": {
        "id": "3lZCymeh6KE1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Below code block needs to be run only once to translate the data and then we will store transalation and use it directly"
      ],
      "metadata": {
        "id": "qF0N05m_6dMO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "!pip install googletrans==4.0.0-rc1\n",
        "\n",
        "from googletrans import Translator\n",
        "import time\n",
        "time.sleep(10)\n",
        "\n",
        "translator = Translator()\n",
        "translations = {}\n",
        "for element in unique_list:\n",
        "  #time.sleep(1)\n",
        "  translations[element] = translator.translate(element).text\n",
        "\n",
        "#for i in translations.items():\n",
        "    #print(i) \n",
        "\n",
        "\n",
        "\n",
        "### Nan was transalated incorrectly so we will remove the Nan translation from dictionary as we would be trating Nan later\n",
        "import numpy as np\n",
        "print(len(translations))\n",
        "translations.pop(np.nan)\n",
        "print(len(translations))\n",
        "\n",
        "\n",
        "### Updating the incorrect translations in the translation dictionary\n",
        "\n",
        "translations.update({'심,뇌혈관계':'Heart, cerebrovascular',\n",
        "'발음이상':'strange pronunciation',\n",
        "'사지 저림':'numb feet and arms',\n",
        "'음성':'negative',\n",
        "'양성':'positive',\n",
        "'남':'male',\n",
        "'어지러움':'Dizziness',\n",
        "'전신쇠약':'body weekness',\n",
        "'오심':'misdiagnosis',\n",
        "'심계항진':'Palpitations',\n",
        "'질출혈':'Vaginal blooding'})\n",
        "\n",
        "\n",
        "### Saving the translations file as json\n",
        "\n",
        "import json\n",
        "\n",
        "with open('/content/drive/MyDrive/Stroke_Prediction/Data/translations_2022.txt','w') as fp:\n",
        "    fp.write(json.dumps(translations))\n",
        "'''"
      ],
      "metadata": {
        "id": "wF6M_z776K7Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Open the saved file to use\n",
        "import json\n",
        "with open('/content/drive/MyDrive/Stroke_Prediction/Data/translations_2022.txt','r') as json_file:\n",
        "   translations = json.load(json_file)"
      ],
      "metadata": {
        "id": "5DR0umFc6pB8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cat_vars_final.append('onset')\n",
        "cat_vars_final.append('test1')\n",
        "### Time and data variables\n",
        "cat_vars_final.append('call_d')\n",
        "cat_vars_final.append('call_t')\n",
        "cat_vars_final.append('jaenan_sn')"
      ],
      "metadata": {
        "id": "8sPsQzax6s6S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# final numerical variables based on our selection\n",
        "num_vars_final = ['age',\n",
        "'dbp1',\n",
        "'sbp1',\n",
        "'pr1',\n",
        "'rr1',\n",
        "'bt1',\n",
        "'spo2_1',\n",
        "'dbp2',\n",
        "'sbp2',\n",
        "'pr2',\n",
        "'rr2',\n",
        "'bt2',\n",
        "'spo2_2']"
      ],
      "metadata": {
        "id": "8poHNTZj62VQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_variables = []\n",
        "for var in cat_vars_final:\n",
        "  final_variables.append(var)\n",
        "\n",
        "for var in num_vars_final:\n",
        "  final_variables.append(var)"
      ],
      "metadata": {
        "id": "y97v79Yz66XA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# null values % in the final categorical and numerical columns\n",
        "final_data = data[final_variables]\n",
        "final_data.shape"
      ],
      "metadata": {
        "id": "3J6yb9VR684z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_data.replace(translations, inplace=True)\n",
        "print(final_data.cv2_cphss.unique())\n",
        "final_data.cv2_cphss.value_counts()"
      ],
      "metadata": {
        "id": "P3_c-2iM6_gN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_data.to_csv('/content/drive/MyDrive/Stroke_Prediction/Data/Stroke_clean_2022.csv', index = False)"
      ],
      "metadata": {
        "id": "KTwl0HE27OPz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}